{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05e13801",
   "metadata": {},
   "source": [
    "# 预处理 Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc67b459",
   "metadata": {},
   "source": [
    "现实生活中，我们会通过多种渠道来获取数据，例如传统的调查问卷、网络爬虫系统或者关系数据库等。\n",
    "在对这些数据进行分析之前通常需要进行**数据预处理**。\n",
    "例如，调查问卷中的某些调查对象可能会选择不回答特定的问题，这就造成数据存在缺失的情况；\n",
    "从网页直接下载的数据同时包含网页结构和网页内容，这就需要对半结构化的数据进行结构化处理等等。\n",
    "此外，数据在采集和传输过程中可能会引入噪音，因此需要离群值检测方法将噪音识别出来；\n",
    "且在使用一些需要进行距离计算的模型之前，要对数据进行标准化处理。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a820b3",
   "metadata": {},
   "source": [
    "<kbd><font color=Red>sklearn.preprocessing</font></kbd>包提供了几个常见的实用功能和变换器类型，用来将原始特征向量更改为更适合机器学习模型的形式。详情参考[英文文档](https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing)或[中文文档](https://www.sklearncn.cn/40/#531)。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1559a3c7",
   "metadata": {},
   "source": [
    "## 1 标准化 Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a71244",
   "metadata": {},
   "source": [
    "数据集的**标准化**对scikit-learn中实现的大多数机器学习算法来说是常见的要求。\n",
    "如果个别特征看起来不是很像标准正态分布（具有零均值和单位方差），那么它们的表现力可能会较差。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19691cf7",
   "metadata": {},
   "source": [
    "在实际情况中，我们经常忽略特征的分布形状，直接经过去均值来对某个特征进行中心化，再通过除以非常量特征（non-constant features）的标准差进行缩放。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4437437",
   "metadata": {},
   "source": [
    "函数<kbd><font color=Blue>scale</font></kbd>为数组形状的数据集的标准化提供了一个快捷实现："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1a9e653",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "X_train = np.array([[ 1., -1.,  2.],\n",
    "                    [ 2.,  0.,  0.],\n",
    "                    [ 0.,  1., -1.]])\n",
    "X_scaled = preprocessing.scale(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb462a76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , -1.22474487,  1.33630621],\n",
       "       [ 1.22474487,  0.        , -0.26726124],\n",
       "       [-1.22474487,  1.22474487, -1.06904497]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3922274",
   "metadata": {},
   "source": [
    "经过缩放后的数据具有零均值以及标准方差："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2634ef50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 均值\n",
    "X_scaled.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eede3186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 方差\n",
    "X_scaled.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1b3373",
   "metadata": {},
   "source": [
    "一种标准化是将特征缩放到给定的最小值和最大值之间，通常在0和1之间，也可以将每个特征的最大绝对值转换至单位大小。\n",
    "可以分别使用<kbd><font color=Blue>MinMaxScaler</font></kbd>和<kbd><font color=Blue>MaxAbsScaler</font></kbd>实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adb9ca49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       , 0.        , 1.        ],\n",
       "       [1.        , 0.5       , 0.33333333],\n",
       "       [0.        , 1.        , 0.        ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.array([[ 1., -1.,  2.],\n",
    "                    [ 2.,  0.,  0.],\n",
    "                    [ 0.,  1., -1.]])\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_train_minmax = min_max_scaler.fit_transform(X_train)\n",
    "X_train_minmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c69124",
   "metadata": {},
   "source": [
    "如果给<kbd><font color=Blue>MinMaxScaler</font></kbd>提供一个明确的<kbd><font color=Red>feature_range=(min, max)</font></kbd>，完整的公式是："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ad6e740",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train\n",
    "max, min = 10, 1\n",
    "X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
    "X_scaled = X_std * (max - min) + min"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced0a35e",
   "metadata": {},
   "source": [
    "<kbd><font color=Blue>MaxAbsScaler</font></kbd>的工作原理非常相似，但是它只通过除以每个特征的最大值将训练数据特征缩放至<kbd><font color=Red>[-1,1]</font></kbd>范围内，这就意味着，训练数据应该是已经零中心化或者是稀疏数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de435583",
   "metadata": {},
   "source": [
    "以下是使用上例中数据运用这个缩放器的示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55380bff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5, -1. ,  1. ],\n",
       "       [ 1. ,  0. ,  0. ],\n",
       "       [ 0. ,  1. , -0.5]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_abs_scaler = preprocessing.MaxAbsScaler()\n",
    "X_train_maxabs = max_abs_scaler.fit_transform(X_train)\n",
    "X_train_maxabs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b26d32",
   "metadata": {},
   "source": [
    "## 2 归一化 Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e815440",
   "metadata": {},
   "source": [
    "**归一化**是**缩放单个样本以具有单位范数**的过程。如果你计划使用二次形式（如点积或任何其他核函数）来量化任何样本间的相似度，则此过程非常有用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e120985",
   "metadata": {},
   "source": [
    "函数<kbd><font color=Blue>normalize</font></kbd>提供了一个快速简单的方法在类似数组的数据集上执行操作，使用<kbd><font color=Red>l1</font></kbd>或<kbd><font color=Red>l2</font></kbd>范数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea65b45e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.40824829, -0.40824829,  0.81649658],\n",
       "       [ 1.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.70710678, -0.70710678]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_normalized = preprocessing.normalize(X_train, norm='l2')\n",
    "X_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38c0ea9",
   "metadata": {},
   "source": [
    "## 3 类别特征编码 Encoding categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a10b4b1",
   "metadata": {},
   "source": [
    "在机器学习中，特征可能不是连续的数值型的而是categorical类型，如性别<kbd><font color=Red>[\"male\",\"female\"]</font></kbd>，我们可以将其编码成整数<kbd><font color=Red>[0,1]</font></kbd>。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758c99a6",
   "metadata": {},
   "source": [
    "要把categorical型特征转换为这样的整数编码(integer codes), 我们可以使用<kbd><font color=Blue>OrdinalEncoder</font></kbd>。\n",
    "这个估计器把每一个categorical feature变换成一个新的整数数字特征（0到 n_categories - 1）:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95ae25a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = preprocessing.OrdinalEncoder()\n",
    "X = [['male', 'from US', 'uses Safari'], ['female', 'from Europe', 'uses Firefox']]\n",
    "enc.fit(X)\n",
    "enc.transform([['female', 'from US', 'uses Safari']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226dd4cb",
   "metadata": {},
   "source": [
    "在上面这个例子中，第一个特征是性别，female被编码为0；第二个特征是来源地，US被编码为1；第三个特征使用的浏览器，Safari被编码为1。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b509e3",
   "metadata": {},
   "source": [
    "这样的整数特征表示并不能在scikit-learn的估计器中直接使用，因为这样的连续输入，估计器会认为类别之间是有序的，但实际却是无序的。\n",
    "(例如：浏览器的类别数据是任意排序的)。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae6a7d2",
   "metadata": {},
   "source": [
    "另外一种将标称型特征转换为能够被scikit-learn中模型使用的编码是**one-of-K**，又称为**独热码**或**dummy encoding**。\n",
    "这种编码类型已经在类<kbd><font color=Blue>OneHotEncoder</font></kbd>中实现。\n",
    "该类把每一个具有n_categories个可能取值的categorical特征变换为长度为n_categories的二进制特征向量，里面只有一个地方是1，其余位置都是0。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7fa1edc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 1., 0., 1.],\n",
       "       [0., 1., 1., 0., 0., 1.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = preprocessing.OneHotEncoder()\n",
    "X = [['male', 'from US', 'uses Safari'], ['female', 'from Europe', 'uses Firefox']]\n",
    "enc.fit(X)\n",
    "enc.transform([['female', 'from US', 'uses Safari'],\n",
    "               ['male', 'from Europe', 'uses Safari']]).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3d4c18",
   "metadata": {},
   "source": [
    "现在我们有了六个特征，第一个位置为1即为female，第二个位置为1即为male，其他位置类似。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb23db6",
   "metadata": {},
   "source": [
    "默认情况下，每个特征使用几维的数值可以从数据集自动推断。而且也可以在属性categories_中找到："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f2e79e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['female', 'male'], dtype=object),\n",
       " array(['from Europe', 'from US'], dtype=object),\n",
       " array(['uses Firefox', 'uses Safari'], dtype=object)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c563ee2",
   "metadata": {},
   "source": [
    "可以使用参数<kbd><font color=Red>categories_</font></kbd>显式地指定这一点。\n",
    "我们的数据集中有两种性别、四种可能的大陆和四种web浏览器:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9dca819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 1., 0., 0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genders = ['female', 'male']\n",
    "locations = ['from Africa', 'from Asia', 'from Europe', 'from US']\n",
    "browsers = ['uses Chrome', 'uses Firefox', 'uses IE', 'uses Safari']\n",
    "enc = preprocessing.OneHotEncoder(categories=[genders, locations, browsers])\n",
    "\n",
    "# Note that for there are missing categorical values for the 2nd and 3rd\n",
    "# feature\n",
    "X = [['male', 'from US', 'uses Safari'], ['female', 'from Europe', 'uses Firefox']]\n",
    "enc.fit(X)\n",
    "enc.transform([['female', 'from Asia', 'uses Chrome']]).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9834391c",
   "metadata": {},
   "source": [
    "如果训练数据可能缺少分类特性，通常最好指定<kbd><font color=Red>handle_unknown</font></kbd>='ignore'，而不是像上面那样手动设置类别。\n",
    "当指定handle_unknown='ignore'，并且在转换过程中遇到未知类别时，不会产生错误，但是为该特性生成的一热编码列将全部为零(handle_unknown='ignore'只支持one hot编码)："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "782b5970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = preprocessing.OneHotEncoder(handle_unknown='ignore')\n",
    "X = [['male', 'from US', 'uses Safari'], ['female', 'from Europe', 'uses Firefox']]\n",
    "enc.fit(X)\n",
    "enc.transform([['female', 'from Asia', 'uses Chrome']]).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed01f88",
   "metadata": {},
   "source": [
    "## 4 离散化 Discretization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c9e138",
   "metadata": {},
   "source": [
    "**离散化**（有些时候叫量化（quantization）或装箱（binning））提供了将连续特征划分为离散特征值的方法。\n",
    "某些具有连续特征的数据集会受益于离散化，因为离散化可以把具有连续属性的数据集变换成只有名义属性(nominal attributes)的数据集。\n",
    "(注：nominal attributes 其实就是 categorical features)。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2210b0d",
   "metadata": {},
   "source": [
    "One-hot编码的离散化特征可以使得一个模型更加的有表现力(expressive)，同时还能保留其可解释性(interpretability)。\n",
    "比如，用离散化器进行预处理可以给线性模型引入非线性。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c4e5ea",
   "metadata": {},
   "source": [
    "<kbd><font color=Blue>KBinsDiscretizer</font></kbd>类使用k个等宽的bins把特征离散化："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd4aa9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[ -3., 5., 15 ],\n",
    "              [  0., 6., 14 ],\n",
    "              [  6., 3., 11 ]])\n",
    "est = preprocessing.KBinsDiscretizer(n_bins=[3, 2, 2], encode='ordinal').fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1685cf01",
   "metadata": {},
   "source": [
    "默认情况下，输出是被 one-hot 编码到一个稀疏矩阵，而且可以使用参数<kbd><font color=Red>encode</font></kbd>进行配置。\n",
    "对每一个特征，<kbd><font color=Red>bin</font></kbd>的边界以及总数目在<kbd><font color=Red>fit</font></kbd>过程中被计算出来，它们将用来定义区间。\n",
    "因此，对现在的示例，这些区间间隔被定义如下：\n",
    "特征1<kbd><font color=Red>[-∞,-1],[-1,2),[2,∞)</font></kbd>，\n",
    "特征2<kbd><font color=Red>[-∞,5),[5,∞)</font></kbd>，\n",
    "特征3<kbd><font color=Red>[-∞,14],[14,∞)</font></kbd>。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2b386c",
   "metadata": {},
   "source": [
    "基于这些<kbd><font color=Red>bin</font></kbd>区间, X 就被变换成下面这样："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30bd76bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [2., 0., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b77d87f",
   "metadata": {},
   "source": [
    "由此产生的数据集包含了有序属性(ordinal attributes),可以被进一步用在类<kbd><font color=Blue>sklearn.pipeline.Pipeline</font></kbd>中。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f476091b",
   "metadata": {},
   "source": [
    "离散化(Discretization)类似于为连续数据构建直方图(histograms)。\n",
    "然而，直方图聚焦于统计特征落在特定的bins里面的数量，而离散化聚焦于给这些bins分配特征取值。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c1073b",
   "metadata": {},
   "source": [
    "<kbd><font color=Blue>KBinsDiscretizer</font></kbd>类实现了不同的binning策略，可以通过参数<kbd><font color=Red>strategy</font></kbd>进行选择。\n",
    "‘uniform’策略使用固定宽度的bins。\n",
    "‘quantile’策略在每个特征上使用分位数(quantiles)值以便具有相同填充的bins。\n",
    "‘kmeans’策略基于在每个特征上独立执行的k-means聚类过程定义bins。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6e320b",
   "metadata": {},
   "source": [
    "## 5 缺失值补全 Imputation of missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26c9a1a",
   "metadata": {},
   "source": [
    "<kbd><font color=Blue>SimpleImputer</font></kbd>类提供了计算缺失值的基本策略。\n",
    "缺失值可以用提供的常数值计算，也可以使用缺失值所在的行/列中的统计数据(平均值、中位数或者众数)来计算。\n",
    "这个类也支持不同的缺失值编码。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfcfa4b",
   "metadata": {},
   "source": [
    "以下代码段演示了如何使用包含缺失值的列(轴0)的平均值来替换编码为<kbd><font color=Red>np.nan</font></kbd>的缺失值："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53ff14ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.         2.        ]\n",
      " [6.         3.66666667]\n",
      " [7.         6.        ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp.fit([[1, 2], [np.nan, 3], [7, 6]])\n",
    "X = [[np.nan, 2], [6, np.nan], [7, 6]]\n",
    "print(imp.transform(X))   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2d6284",
   "metadata": {},
   "source": [
    "一种更复杂的方法是使用<kbd><font color=Blue>IterativeImputer</font></kbd>类，它将每个缺失值的特征建模为其他特征的函数，并使用该估计值进行估算。它以迭代循环方式执行：在每个步骤中，将要素目标列指定为输出y，将其他列视为输入X。使用一个回归器来在已知（未缺失）ｙ的样本上，对（Ｘ，ｙ）进行拟合。然后使用这个回归器来预测缺失的ｙ值。这是以迭代的方式对每个特征进行的，然后重复<kbd><font color=Red>max_iter</font></kbd>轮。最后一轮的计算结果被返回。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4cccbbc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  2.]\n",
      " [ 6. 12.]\n",
      " [ 3.  6.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "imp = IterativeImputer(max_iter=10, random_state=0)\n",
    "imp.fit([[1, 2], [3, 6], [4, 8], [np.nan, 3], [7, np.nan]])\n",
    "\n",
    "X_test = [[np.nan, 2], [6, np.nan], [np.nan, 6]]\n",
    "# the model learns that the second feature is double the first\n",
    "print(np.round(imp.transform(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb936ff9",
   "metadata": {},
   "source": [
    "<kbd><font color=Blue>KNNImputer</font></kbd>类提供了使用k近邻方法填充缺失值的插补。默认情况下，使用支持缺失值的欧几里德距离度量<kbd><font color=Red>nan_euclidean_distances</font></kbd>来查找最近的邻居。每个缺失的特征都是使用具有特征值的<kbd><font color=Red>n_neighbors</font></kbd>个近邻的值来插补的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd621270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1. , 2. , 4. ],\n",
       "       [3. , 4. , 3. ],\n",
       "       [5.5, 6. , 5. ],\n",
       "       [8. , 8. , 7. ]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "nan = np.nan\n",
    "X = [[1, 2, nan], [3, 4, 3], [nan, 6, 5], [8, 8, 7]]\n",
    "imputer = KNNImputer(n_neighbors=2, weights=\"uniform\")\n",
    "imputer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d2dfa7",
   "metadata": {},
   "source": [
    "<kbd><font color=Blue>MissingIndicator</font></kbd>转换器用于将数据集转换为相应的二进制矩阵，以指示数据集中缺失值的存在。这个变换与归算结合起来是有用的。当使用插补时，保存关于哪些值丢失的信息可以提供有用的信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab118bf",
   "metadata": {},
   "source": [
    "<kbd><font color=Red>NaN</font></kbd>通常用作缺少值的占位符。但是，它强制数据类型为浮点数。参数<kbd><font color=Red>missing_values</font></kbd>允许指定其他占位符，如整数。在以下示例中，我们将使用-1作为缺失值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "946fb76b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True, False],\n",
       "       [False,  True,  True],\n",
       "       [False,  True, False]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import MissingIndicator\n",
    "X = np.array([[-1, -1, 1, 3],\n",
    "              [4, -1, 0, -1],\n",
    "              [8, -1, 1, 0]])\n",
    "indicator = MissingIndicator(missing_values=-1)\n",
    "mask_missing_values_only = indicator.fit_transform(X)\n",
    "mask_missing_values_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5c9429",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
